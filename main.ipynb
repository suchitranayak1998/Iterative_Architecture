{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "596474e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\baner\\OneDrive\\Desktop\\Thesis\\Iterative\\Iterative_Architecture\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pipeline_state' from 'util' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Import iterative system components\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplanner_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PlannerAgent, PlannerAgentData, PlanOutput\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01morchestrators\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01morchestrator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IterativeOrchestrator\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreporting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexporters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IterativeReportExporter\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreporting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtask_boards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TaskChecklist\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\baner\\OneDrive\\Desktop\\Thesis\\Iterative\\Iterative_Architecture\\orchestrators\\orchestrator.py:18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m format_pipeline_config_for_prompt\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Tuple, Dict, Any\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreporting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UnitTester, unit_test_report\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIterativeOrchestrator\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\baner\\OneDrive\\Desktop\\Thesis\\Iterative\\Iterative_Architecture\\reporting\\__init__.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexporters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IterativeReportExporter\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtask_boards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TaskChecklist\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msummarizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReportSummarizer\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mQA\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QualityAssurance\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UnitTester, unit_test_report\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\baner\\OneDrive\\Desktop\\Thesis\\Iterative\\Iterative_Architecture\\reporting\\summarizer.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmarkdown\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SystemMessage, HumanMessage\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline_state\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mReportSummarizer\u001b[39;00m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, results: \u001b[38;5;28mlist\u001b[39m, title: \u001b[38;5;28mstr\u001b[39m, output_path: \u001b[38;5;28mstr\u001b[39m, llm, pipeline_state=\u001b[38;5;28;01mNone\u001b[39;00m, phase_name: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'pipeline_state' from 'util' (unknown location)"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "import scipy\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List, Any, Optional, Dict\n",
    "from typing_extensions import TypedDict\n",
    "import re\n",
    "from pprint import pprint\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "import time\n",
    "from pathlib import Path\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import contextlib\n",
    "import base64\n",
    "import plotly\n",
    "from category_encoders import *\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import psutil\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "# Import iterative system components\n",
    "from core.planner_agent import PlannerAgent, PlannerAgentData, PlanOutput\n",
    "from orchestrators.orchestrator import IterativeOrchestrator\n",
    "from reporting.exporters import IterativeReportExporter\n",
    "from reporting.task_boards import TaskChecklist\n",
    "from reporting.summarizer import ReportSummarizer\n",
    "from core.pipeline_state import PipelineState\n",
    "from reporting.QA import QualityAssurance\n",
    "from reporting.validator import unit_test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0fdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM configured successfully!\n"
     ]
    }
   ],
   "source": [
    "# Setup your OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")  # Make sure this is set in your environment\n",
    "\n",
    "if not api_key:\n",
    "    print(\"⚠️ Warning: OPENAI_API_KEY not found. Please set your API key.\")\n",
    "  \n",
    "# Initialize LLM (same as your original setup)\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    #model=\"gpt-4.1-mini\",   # Use gpt-4o if you have access #nano\n",
    "    temperature=0.5,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "llm_coder = ChatOpenAI(\n",
    "    #model=\"gpt-4.1-nano\",\n",
    "    model=\"gpt-4.1-mini\",   # Use gpt-4o if you have access #nano\n",
    "    temperature=0.2,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "print(\"✅ LLM configured successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b749635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset loaded: 2500 rows, 13 columns\n",
      "📋 Columns: ['Area', 'Perimeter', 'Major_Axis_Length', 'Minor_Axis_Length', 'Convex_Area', 'Equiv_Diameter', 'Eccentricity', 'Solidity', 'Extent', 'Roundness', 'Aspect_Ration', 'Compactness', 'Class']\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Load your own CSV\n",
    "df = pd.read_excel('data/Pumpkin_Seeds_Dataset.xlsx')\n",
    "#df_test = pd.read_csv('data/df_test.csv')\n",
    "\n",
    "print(f\"✅ Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"📋 Columns: {list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece051d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate context\n",
    "summary_stats = df.describe(include='all').to_string()\n",
    "column_info = df.dtypes.to_string()\n",
    "col_names = \", \".join(df.columns)\n",
    "context = f\"\"\"## Dataset: Pumpkin Seed Data\n",
    "\n",
    "### Schema:\n",
    "{column_info}\n",
    "\n",
    "### Summary Statistics:\n",
    "{summary_stats}\n",
    "\n",
    "### Column Names:\n",
    "{col_names}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project configuration\n",
    "PROJECT_NAME = \"pumpkin_seeds_iterative_v1\"\n",
    "PIPELINE_TASKS = [\n",
    "    \"Exploratory Data Analysis (EDA)\",\n",
    "    \"Feature Engineering\", \n",
    "    \"Model Selection & Evaluation\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6572994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Iterative Project: pumpkin_seeds_iterative_v1\n",
      "🆕 Starting new iterative project\n",
      "🆕 Starting fresh iterative pipeline...\n",
      "\n",
      "📋 Iterative Execution Plan:\n",
      "   Project: pumpkin_seeds_iterative_v1\n",
      "   Architecture: 3-Agent Iterative (Planner → Developer → Auditor → Developer)\n",
      "   Completed phases: []\n",
      "   Remaining phases: ['Exploratory Data Analysis (EDA)', 'Feature Engineering', 'Model Selection & Evaluation']\n",
      "   DataFrame shape: (2500, 13)\n",
      "\n",
      "🚀 Will execute 3 phase(s) using iterative process\n"
     ]
    }
   ],
   "source": [
    "# Initialize Pipeline State\n",
    "pipeline_state = PipelineState(project_name=PROJECT_NAME)\n",
    "\n",
    "# Check existing project state\n",
    "completed_phases = pipeline_state.get_completed_phases()\n",
    "print(f\"\\n📁 Iterative Project: {PROJECT_NAME}\")\n",
    "\n",
    "if completed_phases:\n",
    "    print(f\"✅ Found existing phases: {completed_phases}\")\n",
    "else:\n",
    "    print(\"🆕 Starting new iterative project\")\n",
    "\n",
    "# Initialize defaults\n",
    "remaining_tasks = PIPELINE_TASKS\n",
    "current_df = df\n",
    "\n",
    "# Auto-resume from last completed phase\n",
    "if completed_phases:\n",
    "    last_phase = completed_phases[-1]\n",
    "    print(f\"🔄 Auto-resuming from last completed phase: {last_phase}\")\n",
    "    pipeline_state.load_from_phase(last_phase)\n",
    "    \n",
    "    try:\n",
    "        last_index = PIPELINE_TASKS.index(last_phase) + 1\n",
    "        remaining_tasks = PIPELINE_TASKS[last_index:]\n",
    "        current_df = pipeline_state.df if pipeline_state.df is not None else df\n",
    "        print(f\"📊 Loaded dataframe shape: {current_df.shape}\")\n",
    "    except (ValueError, IndexError):\n",
    "        print(\"❌ Error in resume logic, starting fresh\")\n",
    "        remaining_tasks = PIPELINE_TASKS\n",
    "else:\n",
    "    print(\"🆕 Starting fresh iterative pipeline...\")\n",
    "    remaining_tasks = PIPELINE_TASKS\n",
    "\n",
    "# Execution Summary\n",
    "print(f\"\\n📋 Iterative Execution Plan:\")\n",
    "print(f\"   Project: {PROJECT_NAME}\")\n",
    "print(f\"   Architecture: 3-Agent Iterative (Planner → Developer → Auditor → Developer)\")\n",
    "print(f\"   Completed phases: {completed_phases}\")\n",
    "print(f\"   Remaining phases: {remaining_tasks}\")\n",
    "print(f\"   DataFrame shape: {current_df.shape}\")\n",
    "\n",
    "if not remaining_tasks:\n",
    "    print(\"\\n✅ All phases completed! Nothing to do.\")\n",
    "    print(\"💡 Tip: Change PROJECT_NAME or delete cache to start over\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\n🚀 Will execute {len(remaining_tasks)} phase(s) using iterative process\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🔄 Running iterative pipeline phase: Exploratory Data Analysis (EDA)\n",
      "============================================================\n",
      "⏱️ Timer started\n",
      "\n",
      "🎯 Starting iterative orchestration...\n",
      "🔒 Data Integrity Validator initialized:\n",
      "   Expected shape: (2500, 13)\n",
      "   Essential columns: 13\n",
      "   Target column: Class\n",
      "\n",
      "🧭 Planning phase (single planner)...\n",
      "📋 Planner produced 1 subtasks.\n",
      "\n",
      "💻 Developer executing subtasks...\n",
      "1. Data Inspection and Summary Statistics\n",
      "📝 No Code History Found\n",
      "plan: subtasks=['Data Inspection and Summary Statistics'] implementation_plan=[\"Begin by inspecting the dataset to understand its structure, data types, and to generate summary statistics for each feature to identify central tendencies, spread, and potential anomalies. Use descriptive statistics to get an overview of the data's distribution and range. Proceed with visualizing the data through histograms, density plots, and scatter plots to explore the distribution of individual features and their relationships with each other, helping to identify patterns or anomalies. Conduct correlation analysis to quantify the relationships between numerical features, which can reveal multicollinearity issues or redundant features. Generate pair plots or scatter matrix plots for visual examination of feature interactions. Detect missing values by calculating null counts per feature and visualize missing data patterns if necessary to understand data completeness. Identify outliers using statistical methods such as z-scores or IQR ranges, and visualize outliers via boxplots to understand their impact and distribution. Analyze the distribution of features through boxplots to detect skewness, outliers, and to compare feature ranges. Finally, evaluate the class distribution to understand the balance or imbalance in the target variable, which is essential for subsequent modeling considerations.\"]\n",
      "🟠 Auditor: REVISE → re-running with improved plan.\n",
      "✅ Developer code executed successfully\n",
      "📄 Extracted Code:\n",
      " import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "# Set seaborn style for better aesthetics\n",
      "sns.set(style=\"whitegrid\")\n",
      "\n",
      "# Identify numerical columns (excluding the target/class column)\n",
      "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
      "\n",
      "# 1. Histograms and Density Plots for each numerical feature\n",
      "for col in num_cols:\n",
      "    plt.figure(figsize=(10,4))\n",
      "    sns.histplot(df[col], kde=True, bins=30, color='skyblue')\n",
      "    plt.title(f'Histogram and Density Plot of {col}')\n",
      "    plt.xlabel(col)\n",
      "    plt.ylabel('Frequency')\n",
      "    plt.tight_layout()\n",
      "\n",
      "# 2. Boxplots for each numerical feature to detect outliers and assess skewness\n",
      "for col in num_cols:\n",
      "    plt.figure(figsize=(8,4))\n",
      "    sns.boxplot(x=df[col], color='lightgreen')\n",
      "    plt.title(f'Boxplot of {col}')\n",
      "    plt.xlabel(col)\n",
      "    plt.tight_layout()\n",
      "\n",
      "# 3. Scatter plots for selected pairs of numerical features to explore relationships\n",
      "# Select a few meaningful pairs based on domain knowledge or correlation (e.g., Area vs Perimeter, Major_Axis_Length vs Minor_Axis_Length)\n",
      "scatter_pairs = [\n",
      "    ('Area', 'Perimeter'),\n",
      "    ('Major_Axis_Length', 'Minor_Axis_Length'),\n",
      "    ('Convex_Area', 'Area'),\n",
      "    ('Equiv_Diameter', 'Area'),\n",
      "    ('Roundness', 'Compactness')\n",
      "]\n",
      "\n",
      "for x_col, y_col in scatter_pairs:\n",
      "    plt.figure(figsize=(7,5))\n",
      "    sns.scatterplot(data=df, x=x_col, y=y_col, hue='Class', palette='Set1', alpha=0.7)\n",
      "    plt.title(f'Scatter Plot of {y_col} vs {x_col}')\n",
      "    plt.xlabel(x_col)\n",
      "    plt.ylabel(y_col)\n",
      "    plt.legend(title='Class')\n",
      "    plt.tight_layout()\n",
      "\n",
      "# 4. Pair plot (scatter matrix) for numerical features colored by Class\n",
      "plt.figure(figsize=(14,14))\n",
      "pairplot = sns.pairplot(df, vars=num_cols, hue='Class', palette='Set2', diag_kind='kde', plot_kws={'alpha':0.6, 's':30})\n",
      "pairplot.fig.suptitle('Pair Plot of Numerical Features Colored by Class', y=1.02)\n",
      "\n",
      "# 5. Visualize missing data patterns if any missing values exist\n",
      "missing_counts = df.isnull().sum()\n",
      "if missing_counts.any():\n",
      "    plt.figure(figsize=(12,6))\n",
      "    sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='viridis')\n",
      "    plt.title('Heatmap of Missing Data Pattern')\n",
      "    plt.xlabel('Features')\n",
      "    plt.tight_layout()\n",
      "    print(\"Missing values detected and visualized.\")\n",
      "else:\n",
      "    print(\"No missing values detected in the dataset.\")\n",
      "\n",
      "# 6. Bar plot for class distribution to understand class balance\n",
      "plt.figure(figsize=(6,4))\n",
      "class_counts = df['Class'].value_counts()\n",
      "sns.barplot(x=class_counts.index, y=class_counts.values, palette='pastel')\n",
      "plt.title('Class Distribution')\n",
      "plt.xlabel('Class')\n",
      "plt.ylabel('Count')\n",
      "plt.tight_layout()\n",
      "\n",
      "# Print class distribution counts\n",
      "print(\"Class distribution counts:\")\n",
      "print(class_counts)\n",
      "📊 Execution Result:\n",
      " No missing values detected in the dataset.\n",
      "Class distribution counts:\n",
      "Class\n",
      "Çerçevelik       1300\n",
      "Ürgüp Sivrisi    1200\n",
      "Name: count, dtype: int64\n",
      "🔒 Validating data integrity...\n",
      "✅ Code executed successfully and passed all data integrity tests\n",
      "📊 Validation: 6/6 tests passed\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     45\u001b[39m summary_path = pipeline_state.save_dir / \u001b[33m\"\u001b[39m\u001b[33mreports\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPROJECT_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask.lower().replace(\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m).replace(\u001b[33m'\u001b[39m\u001b[33m&\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mand\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_summary.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     46\u001b[39m summarizer = ReportSummarizer(\n\u001b[32m     47\u001b[39m     results=phase_results,\n\u001b[32m     48\u001b[39m     task=task,\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m     pipeline_state=pipeline_state\n\u001b[32m     52\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[43msummarizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Save phase to pipeline cache\u001b[39;00m\n\u001b[32m     56\u001b[39m pipeline_state.save_phase(task, [{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m r.items() \u001b[38;5;28;01mif\u001b[39;00m k != \u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m} \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m phase_results])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\baner\\OneDrive\\Desktop\\Thesis\\Iterative\\Iterative_Architecture\\reporting\\summarizer.py:142\u001b[39m, in \u001b[36mReportSummarizer.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    141\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the complete summarization process\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_report_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28mself\u001b[39m.summarize()\n\u001b[32m    144\u001b[39m     \u001b[38;5;28mself\u001b[39m.save_summary()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\baner\\OneDrive\\Desktop\\Thesis\\Iterative\\Iterative_Architecture\\reporting\\summarizer.py:79\u001b[39m, in \u001b[36mReportSummarizer.prepare_report_html\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprepare_report_html\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     78\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convert markdown to HTML\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     md = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     filepath = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtemp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.task.replace(\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.md\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\baner\\OneDrive\\Desktop\\Thesis\\Iterative\\Iterative_Architecture\\reporting\\summarizer.py:26\u001b[39m, in \u001b[36mReportSummarizer.generate_markdown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     23\u001b[39m report = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m# \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.task\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Report - Iterative Process\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, entry \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.results, \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     report += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m## 🔍 Task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msubtask\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# Check if this is iterative process result\u001b[39;00m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33miterative_process\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m entry:\n",
      "\u001b[31mTypeError\u001b[39m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "# Main execution loop\n",
    "for task in remaining_tasks:\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"🔄 Running iterative pipeline phase: {task}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    pipeline_state.clear_validation_log()\n",
    "\n",
    "    # Timer start\n",
    "    start = time.perf_counter()\n",
    "    print(\"⏱️ Timer started\")\n",
    "\n",
    "    # Token tracking\n",
    "    if get_openai_callback is not None:\n",
    "        ctx = get_openai_callback()\n",
    "    else:\n",
    "        ctx = None\n",
    "\n",
    "    with ctx as cb:\n",
    "        # Generate 3-agent personas for iterative workflow\n",
    "\n",
    "        # Get summary of previous phases\n",
    "        prior_summary = pipeline_state.get_contextual_summary(last_n=1)\n",
    "        if prior_summary:\n",
    "            print(f\"\\n📄 Prior context loaded: {len(prior_summary)} characters\")\n",
    "\n",
    "        # Create and run iterative orchestrator\n",
    "        print(f\"\\n🎯 Starting iterative orchestration...\")\n",
    "        orchestrator = IterativeOrchestrator(\n",
    "            df=current_df,\n",
    "            topic=task,\n",
    "            llm=llm,\n",
    "            llm_coder=llm_coder,\n",
    "            summary=prior_summary,\n",
    "            pipeline_state=pipeline_state\n",
    "        )\n",
    "        \n",
    "        # Execute the 4-step iterative process\n",
    "        phase_results = orchestrator.run()\n",
    "\n",
    "        # Update DataFrames from orchestrator\n",
    "        pipeline_state.df = orchestrator.executor.df\n",
    "\n",
    "        # Generate summary using existing summarizer\n",
    "        summary_path = pipeline_state.save_dir / \"reports\" / f\"{PROJECT_NAME}_{task.lower().replace(' ', '_').replace('&', 'and')}_summary.html\"\n",
    "        summarizer = ReportSummarizer(\n",
    "            results=phase_results,\n",
    "            task=task,\n",
    "            output_path=summary_path,\n",
    "            llm=llm_coder,\n",
    "            pipeline_state=pipeline_state\n",
    "        )\n",
    "        summarizer.run()\n",
    "    \n",
    "        # Save phase to pipeline cache\n",
    "        pipeline_state.save_phase(task, [{k: v for k, v in r.items() if k != \"images\"} for r in phase_results])\n",
    "\n",
    "        # Generate iterative reports\n",
    "        print(f\"\\n📄 Generating iterative reports for {task}...\")\n",
    "        \n",
    "        iterative_exporter = IterativeReportExporter(task=task, results=phase_results)\n",
    "        iterative_exporter.export_all(project_name=PROJECT_NAME, save_dir=pipeline_state.save_dir / \"reports\")\n",
    "        \n",
    "        # Validation reports\n",
    "        validation_log = pipeline_state.get_validation_log()\n",
    "        if validation_log:\n",
    "            validation_filename = pipeline_state.save_dir / \"reports\" / f\"{PROJECT_NAME}_{task.lower().replace(' ', '_').replace('&', 'and')}_validation.html\"\n",
    "            unit_test_report(\n",
    "                validation_log=validation_log,\n",
    "                phase_name=task,\n",
    "                project_name=PROJECT_NAME,\n",
    "                filename=validation_filename\n",
    "            )\n",
    "        \n",
    "        # QA reports\n",
    "        qa_agent = QualityAssurance(pipeline_state, llm=llm_coder)\n",
    "        qa_agent.validate_results(phase_results, task)\n",
    "        qa_agent.export_report(phase_name=task, fmt=\"csv\", save_dir=pipeline_state.save_dir / \"reports\")\n",
    "\n",
    "        # Checklist validation\n",
    "        checklist_validator = TaskChecklist(llm=llm_coder, task=task)\n",
    "        report = checklist_validator.validate_phase(task, phase_results)\n",
    "        checklist_validator.export_report(report, pipeline_state.save_dir / \"reports\" / f\"{task.lower().replace(' ', '_')}_checklist_report.json\")\n",
    "\n",
    "        # Timer end\n",
    "        elapsed_sec = time.perf_counter() - start\n",
    "        print(\"\\n\\n\")\n",
    "        print(f\"⏱️  {task} took {elapsed_sec:.2f}s\")\n",
    "        print(f\"🪙  Tokens — total: {cb.total_tokens}, prompt: {cb.prompt_tokens}, completion: {cb.completion_tokens}\")\n",
    "\n",
    "        # Save metrics\n",
    "        metrics_file = pipeline_state.save_dir / \"reports\" / f\"{task}_iterative_metrics.txt\"\n",
    "        with open(metrics_file, \"w\") as f:\n",
    "            f.write(f\"Iterative Process: {task} took {elapsed_sec:.2f}s\\n\")\n",
    "            f.write(f\"Tokens — total: {cb.total_tokens}, prompt: {cb.prompt_tokens}, completion: {cb.completion_tokens}\\n\")\n",
    "            if hasattr(cb, \"total_cost\"):\n",
    "                f.write(f\"Estimated API cost: ${cb.total_cost:.4f}\\n\")\n",
    "            f.write(f\"Architecture: 3-Agent Iterative (Planner → Developer → Auditor → Developer)\\n\")\n",
    "            f.write(f\"Agents: {[agent.name for agent in personas.agents]}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ ITERATIVE PIPELINE EXECUTION COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n📊 Final Iterative Pipeline Summary:\")\n",
    "summary = pipeline_state.get_project_summary()\n",
    "for key, value in summary.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\n🔄 Process Architecture: 3-Agent Iterative\")\n",
    "print(f\"   1. Planner: Strategic planning and task decomposition\")\n",
    "print(f\"   2. Developer: Initial implementation\")\n",
    "print(f\"   3. Auditor: Quality review and feedback\")\n",
    "print(f\"   4. Developer: Refined implementation based on feedback\")\n",
    "\n",
    "print(f\"\\n📁 Generated Files (Project: {PROJECT_NAME}):\")\n",
    "import glob\n",
    "report_dir = pipeline_state.save_dir / \"reports\"\n",
    "if report_dir.exists():\n",
    "    for file_path in report_dir.glob(\"*\"):\n",
    "        if file_path.is_file():\n",
    "            print(f\"   📄 {file_path.name}\")\n",
    "\n",
    "print(f\"\\n💡 To view results:\")\n",
    "print(f\"   📂 Check: {pipeline_state.save_dir}\")\n",
    "print(f\"   📊 Reports: {report_dir}\")\n",
    "print(f\"   🔄 Architecture: Iterative 3-Agent System\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8878b71d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
