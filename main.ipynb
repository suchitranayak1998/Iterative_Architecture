{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "596474e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\baner\\OneDrive\\Desktop\\Thesis\\Iterative\\Iterative_Architecture\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ITERATIVE_PROMPT_TEMPLATES' from 'util.prompt_library' (c:\\Users\\baner\\OneDrive\\Desktop\\Thesis\\Iterative\\Iterative_Architecture\\util\\prompt_library.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Import iterative system components\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplanner_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PlannerAgent, PlannerAgentData, PlanOutput\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01morchestrators\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01morchestrator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IterativeOrchestrator\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreporting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexporters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IterativeReportExporter\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreporting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtask_boards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TaskChecklist\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\baner\\OneDrive\\Desktop\\Thesis\\Iterative\\Iterative_Architecture\\orchestrators\\orchestrator.py:13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline_state\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PipelineState\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompt_library\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ITERATIVE_PROMPT_TEMPLATES\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PIPELINE_CONSTANTS \u001b[38;5;28;01mas\u001b[39;00m PIPELINE_CONFIG\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m format_pipeline_config_for_prompt\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'ITERATIVE_PROMPT_TEMPLATES' from 'util.prompt_library' (c:\\Users\\baner\\OneDrive\\Desktop\\Thesis\\Iterative\\Iterative_Architecture\\util\\prompt_library.py)"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "import scipy\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List, Any, Optional, Dict\n",
    "from typing_extensions import TypedDict\n",
    "import re\n",
    "from pprint import pprint\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "import time\n",
    "from pathlib import Path\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import contextlib\n",
    "import base64\n",
    "import plotly\n",
    "from category_encoders import *\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import psutil\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "# Import iterative system components\n",
    "from core.planner_agent import PlannerAgent, PlannerAgentData, PlanOutput\n",
    "from orchestrators.orchestrator import IterativeOrchestrator\n",
    "from reporting.exporters import IterativeReportExporter\n",
    "from reporting.task_boards import TaskChecklist\n",
    "from reporting.summarizer import ReportSummarizer\n",
    "from core.pipeline_state import PipelineState\n",
    "from reporting.QA import QualityAssurance\n",
    "from reporting.validator import unit_test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0fdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM configured successfully!\n"
     ]
    }
   ],
   "source": [
    "# Setup your OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")  # Make sure this is set in your environment\n",
    "\n",
    "if not api_key:\n",
    "    print(\"‚ö†Ô∏è Warning: OPENAI_API_KEY not found. Please set your API key.\")\n",
    "  \n",
    "# Initialize LLM (same as your original setup)\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    #model=\"gpt-4.1-mini\",   # Use gpt-4o if you have access #nano\n",
    "    temperature=0.5,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "llm_coder = ChatOpenAI(\n",
    "    #model=\"gpt-4.1-nano\",\n",
    "    model=\"gpt-4.1-mini\",   # Use gpt-4o if you have access #nano\n",
    "    temperature=0.2,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LLM configured successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b749635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded: 2500 rows, 13 columns\n",
      "üìã Columns: ['Area', 'Perimeter', 'Major_Axis_Length', 'Minor_Axis_Length', 'Convex_Area', 'Equiv_Diameter', 'Eccentricity', 'Solidity', 'Extent', 'Roundness', 'Aspect_Ration', 'Compactness', 'Class']\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Load your own CSV\n",
    "df = pd.read_excel('data/Pumpkin_Seeds_Dataset.xlsx')\n",
    "#df_test = pd.read_csv('data/df_test.csv')\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"üìã Columns: {list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece051d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate context\n",
    "summary_stats = df.describe(include='all').to_string()\n",
    "column_info = df.dtypes.to_string()\n",
    "col_names = \", \".join(df.columns)\n",
    "context = f\"\"\"## Dataset: Pumpkin Seed Data\n",
    "\n",
    "### Schema:\n",
    "{column_info}\n",
    "\n",
    "### Summary Statistics:\n",
    "{summary_stats}\n",
    "\n",
    "### Column Names:\n",
    "{col_names}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project configuration\n",
    "PROJECT_NAME = \"pumpkin_seeds_iterative_v1\"\n",
    "PIPELINE_TASKS = [\n",
    "    \"Exploratory Data Analysis (EDA)\",\n",
    "    \"Feature Engineering\", \n",
    "    \"Model Selection & Evaluation\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6572994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Iterative Project: pumpkin_seeds_iterative_v1\n",
      "‚úÖ Found existing phases: ['Exploratory Data Analysis (EDA)', 'Feature Engineering']\n",
      "üîÑ Auto-resuming from last completed phase: Feature Engineering\n",
      "üìÑ Dataframe loaded: (2500, 13)\n",
      "‚úÖ Pipeline state loaded from phase: Feature Engineering\n",
      "üìä Loaded 2 subtasks, 1 transforms\n",
      "üìä Loaded dataframe shape: (2500, 13)\n",
      "\n",
      "üìã Iterative Execution Plan:\n",
      "   Project: pumpkin_seeds_iterative_v1\n",
      "   Architecture: 3-Agent Iterative (Planner ‚Üí Developer ‚Üí Auditor ‚Üí Developer)\n",
      "   Completed phases: ['Exploratory Data Analysis (EDA)', 'Feature Engineering']\n",
      "   Remaining phases: ['Model Selection & Evaluation']\n",
      "   DataFrame shape: (2500, 13)\n",
      "\n",
      "üöÄ Will execute 1 phase(s) using iterative process\n"
     ]
    }
   ],
   "source": [
    "# Initialize Pipeline State\n",
    "pipeline_state = PipelineState(project_name=PROJECT_NAME)\n",
    "\n",
    "# Check existing project state\n",
    "completed_phases = pipeline_state.get_completed_phases()\n",
    "print(f\"\\nüìÅ Iterative Project: {PROJECT_NAME}\")\n",
    "\n",
    "if completed_phases:\n",
    "    print(f\"‚úÖ Found existing phases: {completed_phases}\")\n",
    "else:\n",
    "    print(\"üÜï Starting new iterative project\")\n",
    "\n",
    "# Initialize defaults\n",
    "remaining_tasks = PIPELINE_TASKS\n",
    "current_df = df\n",
    "\n",
    "# Auto-resume from last completed phase\n",
    "if completed_phases:\n",
    "    last_phase = completed_phases[-1]\n",
    "    print(f\"üîÑ Auto-resuming from last completed phase: {last_phase}\")\n",
    "    pipeline_state.load_from_phase(last_phase)\n",
    "    \n",
    "    try:\n",
    "        last_index = PIPELINE_TASKS.index(last_phase) + 1\n",
    "        remaining_tasks = PIPELINE_TASKS[last_index:]\n",
    "        current_df = pipeline_state.df if pipeline_state.df is not None else df\n",
    "        print(f\"üìä Loaded dataframe shape: {current_df.shape}\")\n",
    "    except (ValueError, IndexError):\n",
    "        print(\"‚ùå Error in resume logic, starting fresh\")\n",
    "        remaining_tasks = PIPELINE_TASKS\n",
    "else:\n",
    "    print(\"üÜï Starting fresh iterative pipeline...\")\n",
    "    remaining_tasks = PIPELINE_TASKS\n",
    "\n",
    "# Execution Summary\n",
    "print(f\"\\nüìã Iterative Execution Plan:\")\n",
    "print(f\"   Project: {PROJECT_NAME}\")\n",
    "print(f\"   Architecture: 3-Agent Iterative (Planner ‚Üí Developer ‚Üí Auditor ‚Üí Developer)\")\n",
    "print(f\"   Completed phases: {completed_phases}\")\n",
    "print(f\"   Remaining phases: {remaining_tasks}\")\n",
    "print(f\"   DataFrame shape: {current_df.shape}\")\n",
    "\n",
    "if not remaining_tasks:\n",
    "    print(\"\\n‚úÖ All phases completed! Nothing to do.\")\n",
    "    print(\"üí° Tip: Change PROJECT_NAME or delete cache to start over\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\nüöÄ Will execute {len(remaining_tasks)} phase(s) using iterative process\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîÑ Running iterative pipeline phase: Model Selection & Evaluation\n",
      "============================================================\n",
      "‚è±Ô∏è Timer started\n",
      "\n",
      "üìÑ Prior context loaded: 6411 characters\n",
      "\n",
      "üéØ Starting iterative orchestration...\n",
      "üîí Data Integrity Validator initialized:\n",
      "   Expected shape: (2500, 13)\n",
      "   Essential columns: 13\n",
      "   Target column: Class\n",
      "\n",
      "üß≠ Planning phase (single planner)...\n",
      "üìã Planner produced 1 subtasks.\n",
      "\n",
      "üíª Developer executing subtasks...\n",
      "1. Outlier Detection and Capping\n",
      "üìù Number of code snippets in history: 2\n",
      "plan: subtasks=['Outlier Detection and Capping'] implementation_plan=['Begin by applying outlier detection techniques such as Z-score and IQR methods to identify extreme values in numerical features. For each detected outlier, determine appropriate capping bounds based on IQR and cap the outliers at these bounds to reduce their influence. Document the number of outliers capped and the bounds used, then generate boxplots before and after capping to visualize the impact of outlier treatment. Proceed with missing data imputation by analyzing the missingness pattern for each feature, then fill missing values with median for features with less than 5% missing data, ensuring data completeness. After imputation, perform data validation to check for remaining NaNs or infinite values, and handle any anomalies detected. Implement transformation safety checks by verifying that features are positive or apply shifts before log or Box-Cox transformations; if negative or zero values are present, shift data accordingly or fallback to alternative transformations such as cube root. Generate visualizations comparing feature distributions before and after outlier capping and transformations, including histograms and KDE overlays, to assess normalization improvements. Log all transformation parameters, including lambda values for Box-Cox and shift amounts, into a detailed CSV log file. Save these logs systematically to enable reproducibility and transparency. Finally, validate the data post-processing by rechecking for NaN, infinite, or invalid values, and ensure that the transformations have not introduced any data integrity issues, preparing the dataset for subsequent modeling steps.']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'IterativeOrchestrator' object has no attribute 'developer_module'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     29\u001b[39m orchestrator = IterativeOrchestrator(\n\u001b[32m     30\u001b[39m     df=current_df,\n\u001b[32m     31\u001b[39m     topic=task,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     pipeline_state=pipeline_state\n\u001b[32m     36\u001b[39m )\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Execute the 4-step iterative process\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m phase_results = \u001b[43morchestrator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Update DataFrames from orchestrator\u001b[39;00m\n\u001b[32m     42\u001b[39m pipeline_state.df = orchestrator.executor.df\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\baner\\OneDrive\\Desktop\\Thesis\\Iterative\\Iterative_Architecture\\orchestrators\\orchestrator.py:236\u001b[39m, in \u001b[36mIterativeOrchestrator.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    232\u001b[39m instruction = plan\n\u001b[32m    234\u001b[39m df_copy = \u001b[38;5;28mself\u001b[39m.executor.df.copy()\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m success, execution_result, plot_images, attempt_log, code = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdev_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstruction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior_transforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_catalog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m decision: AuditDecisionOutput = \u001b[38;5;28mself\u001b[39m.auditor.review(\n\u001b[32m    239\u001b[39m             subtask=subtask,\n\u001b[32m    240\u001b[39m             plan_text=instruction,\n\u001b[32m    241\u001b[39m             execution_result=execution_result,\n\u001b[32m    242\u001b[39m             task_phase=\u001b[38;5;28mself\u001b[39m.topic\n\u001b[32m    243\u001b[39m         )\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m decision.accept:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\baner\\OneDrive\\Desktop\\Thesis\\Iterative\\Iterative_Architecture\\orchestrators\\orchestrator.py:132\u001b[39m, in \u001b[36mIterativeOrchestrator.dev_call\u001b[39m\u001b[34m(self, subtask, instruction, code_history, prior_transforms, column_catalog, df_copy)\u001b[39m\n\u001b[32m    129\u001b[39m plot_images = []\n\u001b[32m    130\u001b[39m attempt_log = []\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m developer_reply = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdeveloper_module\u001b[49m.generate_code(\n\u001b[32m    133\u001b[39m     subtask=subtask,\n\u001b[32m    134\u001b[39m     manager_instruction=instruction,\n\u001b[32m    135\u001b[39m     code_history=code_history,\n\u001b[32m    136\u001b[39m     prior_transforms=prior_transforms,\n\u001b[32m    137\u001b[39m     column_catalog=column_catalog\n\u001b[32m    138\u001b[39m )\n\u001b[32m    140\u001b[39m code = \u001b[38;5;28mself\u001b[39m.executor.extract_code(developer_reply)\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df_copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'IterativeOrchestrator' object has no attribute 'developer_module'"
     ]
    }
   ],
   "source": [
    "# Main execution loop\n",
    "for task in remaining_tasks:\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"üîÑ Running iterative pipeline phase: {task}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    pipeline_state.clear_validation_log()\n",
    "\n",
    "    # Timer start\n",
    "    start = time.perf_counter()\n",
    "    print(\"‚è±Ô∏è Timer started\")\n",
    "\n",
    "    # Token tracking\n",
    "    if get_openai_callback is not None:\n",
    "        ctx = get_openai_callback()\n",
    "    else:\n",
    "        ctx = None\n",
    "\n",
    "    with ctx as cb:\n",
    "        # Generate 3-agent personas for iterative workflow\n",
    "\n",
    "        # Get summary of previous phases\n",
    "        prior_summary = pipeline_state.get_contextual_summary(last_n=1)\n",
    "        if prior_summary:\n",
    "            print(f\"\\nüìÑ Prior context loaded: {len(prior_summary)} characters\")\n",
    "\n",
    "        # Create and run iterative orchestrator\n",
    "        print(f\"\\nüéØ Starting iterative orchestration...\")\n",
    "        orchestrator = IterativeOrchestrator(\n",
    "            df=current_df,\n",
    "            topic=task,\n",
    "            llm=llm,\n",
    "            llm_coder=llm_coder,\n",
    "            summary=prior_summary,\n",
    "            pipeline_state=pipeline_state\n",
    "        )\n",
    "        \n",
    "        # Execute the 4-step iterative process\n",
    "        phase_results = orchestrator.run()\n",
    "\n",
    "        # Update DataFrames from orchestrator\n",
    "        pipeline_state.df = orchestrator.executor.df\n",
    "\n",
    "        # Generate summary using existing summarizer\n",
    "        summary_path = pipeline_state.save_dir / \"reports\" / f\"{PROJECT_NAME}_{task.lower().replace(' ', '_').replace('&', 'and')}_summary.html\"\n",
    "        summarizer = ReportSummarizer(\n",
    "            results=phase_results,\n",
    "            task=task,\n",
    "            output_path=summary_path,\n",
    "            llm=llm_coder,\n",
    "            pipeline_state=pipeline_state\n",
    "        )\n",
    "        summarizer.run()\n",
    "    \n",
    "        # Save phase to pipeline cache\n",
    "        pipeline_state.save_phase(task, [{k: v for k, v in r.items() if k != \"images\"} for r in phase_results])\n",
    "\n",
    "        # Generate iterative reports\n",
    "        print(f\"\\nüìÑ Generating iterative reports for {task}...\")\n",
    "        \n",
    "        iterative_exporter = IterativeReportExporter(task=task, results=phase_results)\n",
    "        iterative_exporter.export_all(project_name=PROJECT_NAME, save_dir=pipeline_state.save_dir / \"reports\")\n",
    "        \n",
    "        # Validation reports\n",
    "        validation_log = pipeline_state.get_validation_log()\n",
    "        if validation_log:\n",
    "            validation_filename = pipeline_state.save_dir / \"reports\" / f\"{PROJECT_NAME}_{task.lower().replace(' ', '_').replace('&', 'and')}_validation.html\"\n",
    "            unit_test_report(\n",
    "                validation_log=validation_log,\n",
    "                phase_name=task,\n",
    "                project_name=PROJECT_NAME,\n",
    "                filename=validation_filename\n",
    "            )\n",
    "        \n",
    "        # QA reports\n",
    "        qa_agent = QualityAssurance(pipeline_state, llm=llm_coder)\n",
    "        qa_agent.validate_results(phase_results, task)\n",
    "        qa_agent.export_report(phase_name=task, fmt=\"csv\", save_dir=pipeline_state.save_dir / \"reports\")\n",
    "\n",
    "        # Checklist validation\n",
    "        checklist_validator = TaskChecklist(llm=llm_coder, task=task)\n",
    "        report = checklist_validator.validate_phase(task, phase_results)\n",
    "        checklist_validator.export_report(report, pipeline_state.save_dir / \"reports\" / f\"{task.lower().replace(' ', '_')}_checklist_report.json\")\n",
    "\n",
    "        # Timer end\n",
    "        elapsed_sec = time.perf_counter() - start\n",
    "        print(\"\\n\\n\")\n",
    "        print(f\"‚è±Ô∏è  {task} took {elapsed_sec:.2f}s\")\n",
    "        print(f\"ü™ô  Tokens ‚Äî total: {cb.total_tokens}, prompt: {cb.prompt_tokens}, completion: {cb.completion_tokens}\")\n",
    "\n",
    "        # Save metrics\n",
    "        metrics_file = pipeline_state.save_dir / \"reports\" / f\"{task}_iterative_metrics.txt\"\n",
    "        with open(metrics_file, \"w\") as f:\n",
    "            f.write(f\"Iterative Process: {task} took {elapsed_sec:.2f}s\\n\")\n",
    "            f.write(f\"Tokens ‚Äî total: {cb.total_tokens}, prompt: {cb.prompt_tokens}, completion: {cb.completion_tokens}\\n\")\n",
    "            if hasattr(cb, \"total_cost\"):\n",
    "                f.write(f\"Estimated API cost: ${cb.total_cost:.4f}\\n\")\n",
    "            f.write(f\"Architecture: 3-Agent Iterative (Planner ‚Üí Developer ‚Üí Auditor ‚Üí Developer)\\n\")\n",
    "            f.write(f\"Agents: {[agent.name for agent in personas.agents]}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ITERATIVE PIPELINE EXECUTION COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìä Final Iterative Pipeline Summary:\")\n",
    "summary = pipeline_state.get_project_summary()\n",
    "for key, value in summary.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüîÑ Process Architecture: 3-Agent Iterative\")\n",
    "print(f\"   1. Planner: Strategic planning and task decomposition\")\n",
    "print(f\"   2. Developer: Initial implementation\")\n",
    "print(f\"   3. Auditor: Quality review and feedback\")\n",
    "print(f\"   4. Developer: Refined implementation based on feedback\")\n",
    "\n",
    "print(f\"\\nüìÅ Generated Files (Project: {PROJECT_NAME}):\")\n",
    "import glob\n",
    "report_dir = pipeline_state.save_dir / \"reports\"\n",
    "if report_dir.exists():\n",
    "    for file_path in report_dir.glob(\"*\"):\n",
    "        if file_path.is_file():\n",
    "            print(f\"   üìÑ {file_path.name}\")\n",
    "\n",
    "print(f\"\\nüí° To view results:\")\n",
    "print(f\"   üìÇ Check: {pipeline_state.save_dir}\")\n",
    "print(f\"   üìä Reports: {report_dir}\")\n",
    "print(f\"   üîÑ Architecture: Iterative 3-Agent System\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8878b71d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
